{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8765e78a",
   "metadata": {},
   "source": [
    "# Python script to classify 2 different classes of subjects using latent space embeddings of Recurrence plots\n",
    "    Input : Path to folder with Recurrence plot visualisation\n",
    "    Ouput : Classification using the latent space embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be5a48",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-20T11:54:05.055113Z",
     "iopub.status.busy": "2023-11-20T11:54:05.054382Z",
     "iopub.status.idle": "2023-11-20T11:54:12.014528Z",
     "shell.execute_reply": "2023-11-20T11:54:12.013659Z"
    },
    "papermill": {
     "duration": 6.972233,
     "end_time": "2023-11-20T11:54:12.017113",
     "exception": false,
     "start_time": "2023-11-20T11:54:05.044880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.manifold import TSNE\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader, WeightedRandomSampler, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982713a4",
   "metadata": {},
   "source": [
    "In this code we are performing the analysis on Cerebellum network, You can change this by changing the **NETWORK** variable below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below dictionary contains the number of ROIs in each network based on Dosenbach Atlas\n",
    "networks = {\n",
    "    'cerebellum': 18,\n",
    "    'cingulo-opercular':32,\n",
    "    'default_mode':34,\n",
    "    'frontoparietal':21,\n",
    "    'occipital': 22,\n",
    "    'sensorimotor':33\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fdb5a",
   "metadata": {},
   "source": [
    "### Hyperparameters/ Config\n",
    "\n",
    "fine tune the hyperparameters based on your problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433e994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T11:54:12.033445Z",
     "iopub.status.busy": "2023-11-20T11:54:12.032892Z",
     "iopub.status.idle": "2023-11-20T11:54:12.039387Z",
     "shell.execute_reply": "2023-11-20T11:54:12.038464Z"
    },
    "papermill": {
     "duration": 0.016957,
     "end_time": "2023-11-20T11:54:12.041514",
     "exception": false,
     "start_time": "2023-11-20T11:54:12.024557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PRETRAINED = False\n",
    "NETWORK = 'cerebellum'\n",
    "ROIS = networks[NETWORK]\n",
    "SEED = 6\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "OPTIMIZER = 'Adam'\n",
    "DATASET_PATH = f'/Users/ninad/Documents/_CBR/Data/RPlots/ACF/{NETWORK}' # change this path\n",
    "PRETRAINED_MODEL_PATH = '/kaggle/working/autoencoder.pt' # change the path to the model path\n",
    "NUM_EPOCHS = 1\n",
    "EMBEDDING_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3d6f6",
   "metadata": {},
   "source": [
    "#### Comparing input image to the reconstructed one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f729c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T11:54:12.056964Z",
     "iopub.status.busy": "2023-11-20T11:54:12.056669Z",
     "iopub.status.idle": "2023-11-20T11:54:12.065072Z",
     "shell.execute_reply": "2023-11-20T11:54:12.064103Z"
    },
    "papermill": {
     "duration": 0.018498,
     "end_time": "2023-11-20T11:54:12.067198",
     "exception": false,
     "start_time": "2023-11-20T11:54:12.048700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show(data1, data2):\n",
    "    '''function to visually compare the reconstructed image with the input images\n",
    "    Each subject is represented by 2 rows and each pair of column corresponds to a ROI\n",
    "    We can centre Crop the images before feeding to the Autoencoder (Custom Dataset)to get rid of the yellow border ,,\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 10, 2):\n",
    "            ax1 = axes[i][j]\n",
    "            channel1 = data1[i * 5 + j]\n",
    "            ax1.imshow(channel1, cmap='viridis', vmin=-1, vmax=1)  # Specify vmin and vmax for the [0, 1] range\n",
    "            ax1.axis('off')\n",
    "            ax1.set_title('original')\n",
    "\n",
    "            ax2 = axes[i][j + 1]\n",
    "            channel2 = data2[i * 5 + (j // 2)]\n",
    "            ax2.imshow(channel2, cmap='viridis', vmin=-1, vmax=1)  # Specify vmin and vmax for the [0, 1] range\n",
    "            ax2.axis('off')\n",
    "            ax2.set_title('reconstructed')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ffbe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T11:54:12.083025Z",
     "iopub.status.busy": "2023-11-20T11:54:12.082677Z",
     "iopub.status.idle": "2023-11-20T11:54:12.097074Z",
     "shell.execute_reply": "2023-11-20T11:54:12.096052Z"
    },
    "papermill": {
     "duration": 0.024667,
     "end_time": "2023-11-20T11:54:12.099178",
     "exception": false,
     "start_time": "2023-11-20T11:54:12.074511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoderDataset(Dataset):\n",
    "    '''\n",
    "    input: path to all the recurrence plots\n",
    "    ouput: a mutli-channel tensor with channels corresponding to ROIs of a brain network\n",
    "    Dataset class AutoEncoderDataset get's the resized recurrence and stacks the singel channel image to make the input as a multichannel image \n",
    "    ROIi corresponds to ith channel in all datapoints\n",
    "    '''\n",
    "    def __init__(self, root_dir, in_num_channels, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.labels = []\n",
    "        self.samples = []\n",
    "\n",
    "        for class_name in ['healthy', 'mci']:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith(\"14state.png\"):\n",
    "                    paths = [os.path.join(class_dir, file_name.replace(\"14state.png\", f\"{i}state.png\")) for i in range(1,in_num_channels+1)]\n",
    "                    if all(os.path.exists(path) for path in paths):\n",
    "                        label = os.path.join(class_dir, file_name.replace(\"14state.png\", \"state\"))\n",
    "                        new_label = (label.split('/')[-2],label.split('/')[-1][:-9])\n",
    "                        self.samples.append((paths, new_label))\n",
    "                        self.labels.append(new_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        paths, label = self.samples[idx]\n",
    "        images = []\n",
    "\n",
    "        for path in paths:\n",
    "            image = Image.open(path)\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Grayscale(num_output_channels=1),\n",
    "                transforms.CenterCrop((225,224)),\n",
    "                transforms.Lambda(lambda img: img.crop((0, 0, img.width, img.height - 1))),\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "            ])\n",
    "            image_tensor = transform(image)\n",
    "            images.append(image_tensor)\n",
    "            \n",
    "        combined_image = torch.stack(images, dim=1).squeeze()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(combined_image)\n",
    "        else:\n",
    "            image = combined_image\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563180d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T11:54:12.115084Z",
     "iopub.status.busy": "2023-11-20T11:54:12.114806Z",
     "iopub.status.idle": "2023-11-20T11:54:12.134197Z",
     "shell.execute_reply": "2023-11-20T11:54:12.133478Z"
    },
    "papermill": {
     "duration": 0.029847,
     "end_time": "2023-11-20T11:54:12.136008",
     "exception": false,
     "start_time": "2023-11-20T11:54:12.106161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    '''autoencoder architecture'''\n",
    "    def __init__(self, rois, emb_channels):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            # rois x 224 x 224\n",
    "            nn.Conv2d(rois, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # 64 x 112 x 112\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # 128 x 56 x 56\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # 256 x 28 x 28\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # 512 x 28 x 28\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(1024, emb_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "#             nn.BatchNorm2d(emb_channels),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # 1024 x 14 x 14\n",
    "            nn.ConvTranspose2d(emb_channels, 1024, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ConvTranspose2d(1024, 1024, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            # 512 x 28 x 28\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            # 256 x 28 x 28\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # 128 x 56 x 56\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # 64 x 112 x 112\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64, rois, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        bottleneck_output = self.bottleneck(x)\n",
    "        x = self.decoder(bottleneck_output)\n",
    "        return x, bottleneck_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae459e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T11:54:12.150185Z",
     "iopub.status.busy": "2023-11-20T11:54:12.149886Z",
     "iopub.status.idle": "2023-11-20T11:54:20.655884Z",
     "shell.execute_reply": "2023-11-20T11:54:20.654982Z"
    },
    "papermill": {
     "duration": 8.515721,
     "end_time": "2023-11-20T11:54:20.658286",
     "exception": false,
     "start_time": "2023-11-20T11:54:12.142565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder_model = Autoencoder(ROIS, EMBEDDING_CHANNELS)\n",
    "summary(autoencoder_model, input_size=(BATCH_SIZE,ROIS,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572848c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T11:54:20.762433Z",
     "iopub.status.busy": "2023-11-20T11:54:20.762023Z",
     "iopub.status.idle": "2023-11-20T14:13:33.318205Z",
     "shell.execute_reply": "2023-11-20T14:13:33.317074Z"
    },
    "papermill": {
     "duration": 8352.56839,
     "end_time": "2023-11-20T14:13:33.320610",
     "exception": false,
     "start_time": "2023-11-20T11:54:20.752220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%     DATASET CREATION   %%%%%%%%%%%%%%%%%%%%%%%\n",
    "custom_dataset = AutoEncoderDataset(root_dir=DATASET_PATH, in_num_channels=ROIS)\n",
    "test_size = int(len(custom_dataset) * TRAIN_TEST_SPLIT)\n",
    "train_size = len(custom_dataset) - test_size\n",
    "train_ds, test_ds = random_split(custom_dataset, [train_size, test_size])\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE) # set aside test data in the initial part\n",
    "\n",
    "if PRETRAINED :\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%     PRE TRAINED MODEL   %%%%%%%%%%%%%%%%%%%%%%%\n",
    "    autoencoder_model = Autoencoder(ROIS, EMBEDDING_CHANNELS)\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_built() else \"cpu\") # on windows/ linux\n",
    "    device = 'mps' # on macOS\n",
    "    autoencoder_model = autoencoder_model.to(device)\n",
    "    state_dict = torch.load(PRETRAINED_MODEL_PATH)\n",
    "    new_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        new_key = key.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "        new_state_dict[new_key] = value\n",
    "\n",
    "    autoencoder_model.load_state_dict(new_state_dict)\n",
    "    autoencoder_model = DataParallel(autoencoder_model)\n",
    "    criterion = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    criterion_mle = nn.MSELoss()\n",
    "    if OPTIMIZER == 'SGD':\n",
    "        optimizer = optim.SGD(autoencoder_model.parameters(), lr=LEARNING_RATE, momentum=0.9) # change the hyperparamertes if you are using SGD\n",
    "    elif OPTIMIZER == 'Adam':\n",
    "        optimizer = optim.Adam(autoencoder_model.parameters(), lr=LEARNING_RATE)\n",
    "else :\n",
    "    # #%%%%%%%%%%%%%%%%%%%%%%%     MODEL   %%%%%%%%%%%%%%%%%%%%%%%\n",
    "    autoencoder_model = Autoencoder(ROIS, EMBEDDING_CHANNELS)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    criterion_mle = nn.MSELoss()\n",
    "    autoencoder_model = autoencoder_model.to(device)\n",
    "    autoencoder_model = DataParallel(autoencoder_model)\n",
    "    if OPTIMIZER == 'SGD':\n",
    "        optimizer = optim.SGD(autoencoder_model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    elif OPTIMIZER == 'Adam':\n",
    "        optimizer = optim.Adam(autoencoder_model.parameters(), lr=LEARNING_RATE)\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%     MODEL TRAINING   %%%%%%%%%%%%%%%%%%%%%%%\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        autoencoder_model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_dl:\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = autoencoder_model(inputs)\n",
    "            loss_ssim = 1 - criterion(outputs[0], inputs)\n",
    "            loss_mle = criterion_mle(outputs[0],inputs)\n",
    "            loss = loss_mle+loss_ssim\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            criterion.update(outputs[0],inputs)\n",
    "\n",
    "        autoencoder_model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dl:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = autoencoder_model(inputs)\n",
    "                loss_ssim = 1 - criterion(outputs[0], inputs)\n",
    "                loss_mle = criterion_mle(outputs[0],inputs)\n",
    "                loss = loss_mle+loss_ssim\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.5f} Val Loss: {val_loss:.5f}\")\n",
    "        # if (epoch + 1) % 5 == 0:\n",
    "        #     print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.5f} Val Loss: {val_loss:.5f}\")\n",
    "\n",
    "    # torch.save(autoencoder_model.state_dict(), f'{NETWORK}_autoencoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9b477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:13:33.368389Z",
     "iopub.status.busy": "2023-11-20T14:13:33.367622Z",
     "iopub.status.idle": "2023-11-20T14:13:42.335636Z",
     "shell.execute_reply": "2023-11-20T14:13:42.334730Z"
    },
    "papermill": {
     "duration": 8.997634,
     "end_time": "2023-11-20T14:13:42.341598",
     "exception": false,
     "start_time": "2023-11-20T14:13:33.343964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder_model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = autoencoder_model(inputs)\n",
    "        for k in range(5):\n",
    "            show(inputs[k].to('cpu').numpy(), outputs[0][k].to('cpu').numpy())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f419a24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:13:42.456995Z",
     "iopub.status.busy": "2023-11-20T14:13:42.456648Z",
     "iopub.status.idle": "2023-11-20T14:13:43.276302Z",
     "shell.execute_reply": "2023-11-20T14:13:43.275220Z"
    },
    "papermill": {
     "duration": 0.880445,
     "end_time": "2023-11-20T14:13:43.278911",
     "exception": false,
     "start_time": "2023-11-20T14:13:42.398466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embedded_data = {'healthy':{}, 'mci':{}}\n",
    "# embedding_dataset = AutoEncoderDataset(root_dir=DATASET_PATH, in_num_channels=ROIS)\n",
    "# embedding_dl = DataLoader(embedding_dataset, batch_size=BATCH_SIZE)\n",
    "# embedding_train_dl = train_dl\n",
    "# embedding_test_dl = test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed2997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:13:43.395156Z",
     "iopub.status.busy": "2023-11-20T14:13:43.394779Z",
     "iopub.status.idle": "2023-11-20T14:13:50.476901Z",
     "shell.execute_reply": "2023-11-20T14:13:50.476034Z"
    },
    "papermill": {
     "duration": 7.142508,
     "end_time": "2023-11-20T14:13:50.479216",
     "exception": false,
     "start_time": "2023-11-20T14:13:43.336708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedded_data = {'healthy':{}, 'mci':{}}\n",
    "autoencoder_model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_dl:\n",
    "        inputs = inputs.to(device)\n",
    "        _, embedding = autoencoder_model(inputs)\n",
    "        for k, (class_, subj) in enumerate(zip(labels[0], labels[1])):\n",
    "            subj_no = int(subj[-2:])\n",
    "            if subj_no < 0 :\n",
    "                embedded_data[class_][subj_no*(-1)] = embedding[k].cpu().numpy()\n",
    "            else:\n",
    "                embedded_data[class_][subj_no] = embedding[k].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data_test = {'healthy':{}, 'mci':{}}\n",
    "autoencoder_model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs = inputs.to(device)\n",
    "        _, embedding = autoencoder_model(inputs)\n",
    "        for k, (class_, subj) in enumerate(zip(labels[0], labels[1])):\n",
    "            subj_no = int(subj[-2:])\n",
    "            if subj_no < 0 :\n",
    "                embedded_data_test[class_][subj_no*(-1)] = embedding[k].cpu().numpy()\n",
    "            else:\n",
    "                embedded_data_test[class_][subj_no] = embedding[k].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3fb3b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:13:50.586948Z",
     "iopub.status.busy": "2023-11-20T14:13:50.586629Z",
     "iopub.status.idle": "2023-11-20T14:13:50.752772Z",
     "shell.execute_reply": "2023-11-20T14:13:50.751386Z"
    },
    "papermill": {
     "duration": 0.224347,
     "end_time": "2023-11-20T14:13:50.756716",
     "exception": false,
     "start_time": "2023-11-20T14:13:50.532369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,10))\n",
    "for i in range(1, 5*EMBEDDING_CHANNELS, EMBEDDING_CHANNELS):\n",
    "    for channel in range(EMBEDDING_CHANNELS):\n",
    "        plt.subplot(5, EMBEDDING_CHANNELS, i + channel)\n",
    "        subj = list(embedded_data['healthy'].keys())[i]\n",
    "        plt.imshow(embedded_data['healthy'][subj][channel])\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15779548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:13:50.914748Z",
     "iopub.status.busy": "2023-11-20T14:13:50.914068Z",
     "iopub.status.idle": "2023-11-20T14:13:51.083975Z",
     "shell.execute_reply": "2023-11-20T14:13:51.082534Z"
    },
    "papermill": {
     "duration": 0.230158,
     "end_time": "2023-11-20T14:13:51.088076",
     "exception": false,
     "start_time": "2023-11-20T14:13:50.857918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,10))\n",
    "for i in range(1, 5*EMBEDDING_CHANNELS, EMBEDDING_CHANNELS):\n",
    "    for channel in range(EMBEDDING_CHANNELS):\n",
    "        plt.subplot(5, EMBEDDING_CHANNELS, i + channel)\n",
    "        subj = list(embedded_data['mci'].keys())[i]\n",
    "        plt.imshow(embedded_data['mci'][subj][channel])\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482ae0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:13:51.250759Z",
     "iopub.status.busy": "2023-11-20T14:13:51.250390Z",
     "iopub.status.idle": "2023-11-20T14:13:51.260289Z",
     "shell.execute_reply": "2023-11-20T14:13:51.259473Z"
    },
    "papermill": {
     "duration": 0.069452,
     "end_time": "2023-11-20T14:13:51.262248",
     "exception": false,
     "start_time": "2023-11-20T14:13:51.192796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddedDataset(Dataset):\n",
    "    '''Dataset class for classifying the latent space representation\n",
    "    '''\n",
    "    def __init__(self, class1_dict, class2_dict):\n",
    "        self.class1_data = list(class1_dict.values())\n",
    "        self.class2_data = list(class2_dict.values())\n",
    "        self.class1_labels = [0] * len(self.class1_data)\n",
    "        self.class2_labels = [1] * len(self.class2_data)\n",
    "        self.data = self.class1_data + self.class2_data\n",
    "        self.labels = self.class1_labels + self.class2_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.Tensor(self.data[index])\n",
    "        label = self.labels[index]\n",
    "        return data, label\n",
    "\n",
    "emb_data = EmbeddedDataset(embedded_data['healthy'], embedded_data['mci'])\n",
    "val_size = int(len(emb_data) * 0.15)\n",
    "train_size = len(emb_data) - val_size\n",
    "train_ds, val_ds = random_split(emb_data, [train_size, val_size])\n",
    "train_dl = DataLoader(train_ds, batch_size=8)\n",
    "val_dl = DataLoader(val_ds, batch_size=8)\n",
    "emb_data_test = EmbeddedDataset(embedded_data_test['healthy'], embedded_data_test['mci'])\n",
    "test_dl = DataLoader(emb_data_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558b210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:13:51.370930Z",
     "iopub.status.busy": "2023-11-20T14:13:51.370545Z",
     "iopub.status.idle": "2023-11-20T14:13:51.379844Z",
     "shell.execute_reply": "2023-11-20T14:13:51.379057Z"
    },
    "papermill": {
     "duration": 0.066391,
     "end_time": "2023-11-20T14:13:51.381818",
     "exception": false,
     "start_time": "2023-11-20T14:13:51.315427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # input 1 x 14 x 14\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*7*7, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # Two output classes for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a835c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:13:51.493455Z",
     "iopub.status.busy": "2023-11-20T14:13:51.493099Z",
     "iopub.status.idle": "2023-11-20T14:14:06.531156Z",
     "shell.execute_reply": "2023-11-20T14:14:06.530104Z"
    },
    "papermill": {
     "duration": 15.094482,
     "end_time": "2023-11-20T14:14:06.533486",
     "exception": false,
     "start_time": "2023-11-20T14:13:51.439004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classfier_model = SimpleCNN(EMBEDDING_CHANNELS)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = classfier_model.to(device)\n",
    "model = DataParallel(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_type = 'Adam'\n",
    "learning_rate = 5e-4\n",
    "\n",
    "if optimizer_type == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "elif optimizer_type == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%     MODEL TRAINING   %%%%%%%%%%%%%%%%%%%%%%%\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accu = []\n",
    "val_accu = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for inputs, labels in train_dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dl:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()  # Accumulate validation loss\n",
    "\n",
    "            # Compute validation accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    val_loss /= len(val_dl)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accu.append(train_accuracy)\n",
    "    val_accu.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]: \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f6f86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:14:06.654163Z",
     "iopub.status.busy": "2023-11-20T14:14:06.653770Z",
     "iopub.status.idle": "2023-11-20T14:14:06.919399Z",
     "shell.execute_reply": "2023-11-20T14:14:06.918365Z"
    },
    "papermill": {
     "duration": 0.327574,
     "end_time": "2023-11-20T14:14:06.921520",
     "exception": false,
     "start_time": "2023-11-20T14:14:06.593946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "plt.plot(epochs, train_losses, marker='o')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742ce3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:14:07.046180Z",
     "iopub.status.busy": "2023-11-20T14:14:07.045804Z",
     "iopub.status.idle": "2023-11-20T14:14:07.326506Z",
     "shell.execute_reply": "2023-11-20T14:14:07.325500Z"
    },
    "papermill": {
     "duration": 0.346027,
     "end_time": "2023-11-20T14:14:07.328582",
     "exception": false,
     "start_time": "2023-11-20T14:14:06.982555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, val_losses, marker='o', color = 'orange')\n",
    "plt.title('Validation Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cc86d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:14:07.464486Z",
     "iopub.status.busy": "2023-11-20T14:14:07.463937Z",
     "iopub.status.idle": "2023-11-20T14:14:07.778370Z",
     "shell.execute_reply": "2023-11-20T14:14:07.777345Z"
    },
    "papermill": {
     "duration": 0.388738,
     "end_time": "2023-11-20T14:14:07.780679",
     "exception": false,
     "start_time": "2023-11-20T14:14:07.391941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_accu, marker='o')\n",
    "plt.plot(epochs, val_accu, marker='o')\n",
    "plt.title('Traning and Validation Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy in %')\n",
    "plt.ylim(0,120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81073c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T14:14:07.908702Z",
     "iopub.status.busy": "2023-11-20T14:14:07.907860Z",
     "iopub.status.idle": "2023-11-20T14:14:08.315649Z",
     "shell.execute_reply": "2023-11-20T14:14:08.314565Z"
    },
    "papermill": {
     "duration": 0.472533,
     "end_time": "2023-11-20T14:14:08.318019",
     "exception": false,
     "start_time": "2023-11-20T14:14:07.845486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 2  \n",
    "conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Convert to int (0 or 1)\n",
    "\n",
    "        conf_matrix += confusion_matrix(labels.cpu(), predicted.cpu(), labels=[0, 1])\n",
    "\n",
    "\n",
    "TP = conf_matrix[1, 1]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
    "            yticklabels=[\"True 0\", \"True 1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.suptitle(f'Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17333c",
   "metadata": {
    "papermill": {
     "duration": 0.059801,
     "end_time": "2023-11-20T14:14:08.441507",
     "exception": false,
     "start_time": "2023-11-20T14:14:08.381706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4001372,
     "sourceId": 6965032,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8410.041528,
   "end_time": "2023-11-20T14:14:11.466581",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-20T11:54:01.425053",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
